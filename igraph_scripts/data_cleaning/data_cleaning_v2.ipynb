{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidates code from some other scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding leks with the same coordinates. Kept the lower of the IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lek_id</th>\n",
       "      <th>year</th>\n",
       "      <th>activity</th>\n",
       "      <th>x_easting</th>\n",
       "      <th>y_northing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>672527</td>\n",
       "      <td>3730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>True</td>\n",
       "      <td>672527</td>\n",
       "      <td>3730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>672527</td>\n",
       "      <td>3730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>672527</td>\n",
       "      <td>3730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>669625</td>\n",
       "      <td>3729786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lek_id  year  activity  x_easting  y_northing\n",
       "0       2  2007      True     672527     3730500\n",
       "1       2  2008      True     672527     3730500\n",
       "2       2  2009      True     672527     3730500\n",
       "3       2  2010      True     672527     3730500\n",
       "4       4  2007      True     669625     3729786"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/raw_data/lek_data_binary_year_activity_for_py.csv\")\n",
    "#df.head()\n",
    "\n",
    "# Group by 'site' and 'year', and aggregate by taking the max for 'activity'\n",
    "df = df.groupby(['lek_id', 'year'], as_index=False).agg({'activity': 'max',\n",
    "                                                                'x_easting' : 'first',\n",
    "                                                                'y_northing' : 'first'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'shared_coordinates_rows.csv' and 'shared_leks_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is already loaded as `df`\n",
    "\n",
    "# Step 1: Keep only unique combinations of lek_id, northings, and eastings\n",
    "unique_leks = df[['lek_id', 'y_northing', 'x_easting']].drop_duplicates()\n",
    "\n",
    "# Step 2: Create a new column combining northings and eastings\n",
    "unique_leks['coordinates'] = unique_leks['y_northing'].astype(str) + \"_\" + unique_leks['x_easting'].astype(str)\n",
    "\n",
    "# Step 3: Find lek_ids that share the same coordinates\n",
    "shared_coords = unique_leks[unique_leks.duplicated(subset='coordinates', keep=False)]\n",
    "\n",
    "# Step 4: Group by the combined coordinates and collect lek_ids that share the same coordinates\n",
    "shared_leks = shared_coords.groupby('coordinates')['lek_id'].unique().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "shared_leks.columns = ['coordinates', 'shared_lek_ids']\n",
    "\n",
    "# Save to CSV if needed\n",
    "shared_coords.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_coordinates_rows.csv\", index=False)  # Rows with shared coordinates\n",
    "shared_leks.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_leks_summary.csv\", index=False)  # Summary of shared lek_ids by coordinates\n",
    "\n",
    "print(\"Results saved to 'shared_coordinates_rows.csv' and 'shared_leks_summary.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-checking to make sure none were missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'shared_coordinates_rows_check.csv' and 'shared_leks_summary_check.csv'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_year_cleaned.csv\")\n",
    "\n",
    "# Assuming your DataFrame is already loaded as `df`\n",
    "\n",
    "# Step 1: Keep only unique combinations of lek_id, northings, and eastings\n",
    "unique_leks = df[['lek_id', 'y_northing', 'x_easting']].drop_duplicates()\n",
    "\n",
    "# Step 2: Create a new column combining northings and eastings\n",
    "unique_leks['coordinates'] = unique_leks['y_northing'].astype(str) + \"_\" + unique_leks['x_easting'].astype(str)\n",
    "\n",
    "# Step 3: Find lek_ids that share the same coordinates\n",
    "shared_coords = unique_leks[unique_leks.duplicated(subset='coordinates', keep=False)]\n",
    "\n",
    "# Step 4: Group by the combined coordinates and collect lek_ids that share the same coordinates\n",
    "shared_leks = shared_coords.groupby('coordinates')['lek_id'].unique().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "shared_leks.columns = ['coordinates', 'shared_lek_ids']\n",
    "\n",
    "# Save to CSV if needed\n",
    "shared_coords.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_coordinates_rows_check.csv\", index=False)  # Rows with shared coordinates\n",
    "shared_leks.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_leks_summary_check.csv\", index=False)  # Summary of shared lek_ids by coordinates\n",
    "\n",
    "print(\"Results saved to 'shared_coordinates_rows_check.csv' and 'shared_leks_summary_check.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that all data is across the same time scale and that know if a year was surveyed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condenses the sheets so that their aren't multiple rows for each year of data, just one for it was true or not\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_year_cleaned.csv\")\n",
    "\n",
    "df = df[df['year'] > 1969]\n",
    "\n",
    "# Ensure 'activity' is a boolean (if stored as strings like \"true\"/\"false\")\n",
    "df['activity'] = df['activity'].astype(bool)\n",
    "\n",
    "# Aggregate by lek and year, keeping the maximum value of 'activity' (True > False)\n",
    "df = df.groupby(['lek_id', 'year'], as_index=False).agg({\n",
    "    'y_northing': 'first',  # Keeps the first value, assuming it's consistent\n",
    "    'x_easting': 'first',   # Keeps the first value, assuming it's consistent\n",
    "    'activity': 'max'      # Returns True if any activity is True for the group\n",
    "})\n",
    "\n",
    "# Save the result back to a CSV if needed\n",
    "df.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_year_clean_condensed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added Texas lek locations before next code block below. Gave arbitrary year of recording '2000', but left the activity column blank for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'shared_coordinates_rows_check.csv' and 'shared_leks_summary_check.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_year_clean_condensed_texas_added.csv\")\n",
    "\n",
    "# Assuming your DataFrame is already loaded as `df`\n",
    "\n",
    "# Step 1: Keep only unique combinations of lek_id, northings, and eastings\n",
    "unique_leks = df[['lek_id', 'y_northing', 'x_easting']].drop_duplicates()\n",
    "\n",
    "# Step 2: Create a new column combining northings and eastings\n",
    "unique_leks['coordinates'] = unique_leks['y_northing'].astype(str) + \"_\" + unique_leks['x_easting'].astype(str)\n",
    "\n",
    "# Step 3: Find lek_ids that share the same coordinates\n",
    "shared_coords = unique_leks[unique_leks.duplicated(subset='coordinates', keep=False)]\n",
    "\n",
    "# Step 4: Group by the combined coordinates and collect lek_ids that share the same coordinates\n",
    "shared_leks = shared_coords.groupby('coordinates')['lek_id'].unique().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "shared_leks.columns = ['coordinates', 'shared_lek_ids']\n",
    "\n",
    "# Save to CSV if needed\n",
    "shared_coords.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_coordinates_rows_check_texas.csv\", index=False)  # Rows with shared coordinates\n",
    "shared_leks.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_leks_summary_check_texas.csv\", index=False)  # Summary of shared lek_ids by coordinates\n",
    "\n",
    "print(\"Results saved to 'shared_coordinates_rows_check.csv' and 'shared_leks_summary_check.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lek_id  year  x_easting  y_northing      activity\n",
      "0           2  1971     672527     3730500  not surveyed\n",
      "1           2  1972     672527     3730500  not surveyed\n",
      "2           2  1973     672527     3730500  not surveyed\n",
      "3           2  1974     672527     3730500  not surveyed\n",
      "4           2  1975     672527     3730500  not surveyed\n",
      "...       ...   ...        ...         ...           ...\n",
      "66859   95087  2014     697851     3699492  not surveyed\n",
      "66860   95087  2015     697851     3699492  not surveyed\n",
      "66861   95087  2016     697851     3699492  not surveyed\n",
      "66862   95087  2017     697851     3699492  not surveyed\n",
      "66863   95087  2018     697851     3699492  not surveyed\n",
      "\n",
      "[66864 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# creates the same span of years for all the leks, then indicates if activity was recorded or not or if the lek was surveyed that year.\n",
    "\n",
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_year_clean_condensed_texas_added.csv\")\n",
    "\n",
    "\n",
    "# Define the range of years you want\n",
    "years = range(df['year'].min(), df['year'].max() + 1)\n",
    "\n",
    "# Create a complete DataFrame for all leks and years\n",
    "leks = df['lek_id'].unique()\n",
    "complete_index = pd.MultiIndex.from_product([leks, years], names=['lek_id', 'year'])\n",
    "complete_df = pd.DataFrame(index=complete_index).reset_index()\n",
    "\n",
    "# Check the columns in the original DataFrame\n",
    "#print(\"Original DataFrame columns:\", df.columns)\n",
    "\n",
    "# Create a unique DataFrame to maintain site info and coordinates\n",
    "unique_sites_df = df[['lek_id', 'x_easting', 'y_northing']].drop_duplicates()\n",
    "\n",
    "# Merge the unique sites DataFrame with the complete DataFrame\n",
    "result_df = pd.merge(complete_df, unique_sites_df, on='lek_id', how='left')\n",
    "\n",
    "# Now merge the activity data\n",
    "df = pd.merge(result_df, df[['lek_id', 'year', 'activity']], on=['lek_id', 'year'], how='left')\n",
    "\n",
    "# Replace NaN values in the 'activity' column with \"not surveyed\"\n",
    "df['activity'] = df['activity'].fillna('not surveyed')\n",
    "\n",
    "df.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_yearly_activity_w_tx.csv\", index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run if want to get a rolling level of activity - not ever run before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'year' column to datetime for time calculations\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "\n",
    "# Sort by lek and year\n",
    "df = df.sort_values(by=['lek_id', 'year'])\n",
    "\n",
    "# Initialize a new column for activity in the last five years\n",
    "df['active_last_5_years'] = False\n",
    "\n",
    "# Modified function to check last 5 years and reset the index for proper alignment\n",
    "def check_activity_last_5_years(group):\n",
    "    years = group['year'].dt.year\n",
    "    activity_status = []\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        # Define the 5-year range\n",
    "        start_year = years.iloc[i] - 4\n",
    "        # Slice to get the last 5 years' activities\n",
    "        recent_activities = group[(years >= start_year) & (years <= years.iloc[i])]['activity']\n",
    "        \n",
    "        # Check if 'True' exists in the last 5 years\n",
    "        if True in recent_activities.values:\n",
    "            activity_status.append('True')\n",
    "        #elif 'not surveyed' not in recent_activities.values and recent_activities.size > 0:\n",
    "        #    activity_status.append('Not Surveyed Over 5 Years')\n",
    "        else:\n",
    "            activity_status.append('Inactive or not surveyed')\n",
    "    \n",
    "    # Return a properly aligned series with the original index\n",
    "    return pd.Series(activity_status, index=group.index)\n",
    "\n",
    "# Apply the function by lek\n",
    "df['active_last_5_years'] = df.groupby('lek_id', group_keys=False).apply(check_activity_last_5_years)\n",
    "\n",
    "df.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/lek_data_binary_rolling_activity.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With unknown lek locations added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/unk_loc_leks_data/lek_data_binary_year_clean_unk_loc_leks_added.csv\")\n",
    "\n",
    "# Assuming your DataFrame is already loaded as `df`\n",
    "\n",
    "# Step 1: Keep only unique combinations of lek_id, northings, and eastings\n",
    "unique_leks = df[['lek_id', 'y_northing', 'x_easting']].drop_duplicates()\n",
    "\n",
    "# Step 2: Create a new column combining northings and eastings\n",
    "unique_leks['coordinates'] = unique_leks['y_northing'].astype(str) + \"_\" + unique_leks['x_easting'].astype(str)\n",
    "\n",
    "# Step 3: Find lek_ids that share the same coordinates\n",
    "shared_coords = unique_leks[unique_leks.duplicated(subset='coordinates', keep=False)]\n",
    "\n",
    "# Step 4: Group by the combined coordinates and collect lek_ids that share the same coordinates\n",
    "shared_leks = shared_coords.groupby('coordinates')['lek_id'].unique().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "shared_leks.columns = ['coordinates', 'shared_lek_ids']\n",
    "\n",
    "# Save to CSV if needed\n",
    "shared_coords.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_coordinates_rows_check_unk_loc_leks.csv\", index=False)  # Rows with shared coordinates\n",
    "shared_leks.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/shared_leks_summary_check_unk_loc_leks.csv\", index=False)  # Summary of shared lek_ids by coordinates\n",
    "\n",
    "print(\"Results saved to 'shared_coordinates_rows_check.csv' and 'shared_leks_summary_check.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lek_id  year  x_easting  y_northing      activity\n",
      "0           2  1971     672527     3730500  not surveyed\n",
      "1           2  1972     672527     3730500  not surveyed\n",
      "2           2  1973     672527     3730500  not surveyed\n",
      "3           2  1974     672527     3730500  not surveyed\n",
      "4           2  1975     672527     3730500  not surveyed\n",
      "...       ...   ...        ...         ...           ...\n",
      "73339   95222  2014     679408     3597474  not surveyed\n",
      "73340   95222  2015     679408     3597474  not surveyed\n",
      "73341   95222  2016     679408     3597474  not surveyed\n",
      "73342   95222  2017     679408     3597474         False\n",
      "73343   95222  2018     679408     3597474  not surveyed\n",
      "\n",
      "[73344 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# creates the same span of years for all the leks, then indicates if activity was recorded or not or if the lek was surveyed that year.\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/unk_loc_leks_data/lek_data_binary_year_clean_unk_loc_leks_added.csv\")\n",
    "\n",
    "\n",
    "# Define the range of years you want\n",
    "years = range(df['year'].min(), df['year'].max() + 1)\n",
    "\n",
    "# Create a complete DataFrame for all leks and years\n",
    "leks = df['lek_id'].unique()\n",
    "complete_index = pd.MultiIndex.from_product([leks, years], names=['lek_id', 'year'])\n",
    "complete_df = pd.DataFrame(index=complete_index).reset_index()\n",
    "\n",
    "# Check the columns in the original DataFrame\n",
    "#print(\"Original DataFrame columns:\", df.columns)\n",
    "\n",
    "# Create a unique DataFrame to maintain site info and coordinates\n",
    "unique_sites_df = df[['lek_id', 'x_easting', 'y_northing']].drop_duplicates()\n",
    "\n",
    "# Merge the unique sites DataFrame with the complete DataFrame\n",
    "result_df = pd.merge(complete_df, unique_sites_df, on='lek_id', how='left')\n",
    "\n",
    "# Now merge the activity data\n",
    "df = pd.merge(result_df, df[['lek_id', 'year', 'activity']], on=['lek_id', 'year'], how='left')\n",
    "\n",
    "# Replace NaN values in the 'activity' column with \"not surveyed\"\n",
    "df['activity'] = df['activity'].fillna('not surveyed')\n",
    "\n",
    "df.to_csv(\"E:/!!Research/!!!Data/graph_analysis/lek_data/cleaned_data/unk_loc_leks_data/lek_data_binary_yearly_activity_unk_loc_leks.csv\", index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
