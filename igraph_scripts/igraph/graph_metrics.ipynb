{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File for finding the metrics of each of the graphs at different distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "import graph_functions as graf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_classified_thumbnails(folder_directory, data_folder, shp_dir, \n",
    "                                   n_clusters = 10, fishnet_rows = 5, \n",
    "                                   fishnet_cols = 5, scale = 1, xmeans = False, error_log = False):\n",
    "    \n",
    "    # cleaning out any extra files in case ran previously\n",
    "    delete_file_path = f'{shp_dir}/'\n",
    "    delete_file_paths = os.listdir(delete_file_path)\n",
    "    for file in delete_file_paths:\n",
    "        if (re.search(r'[0-9]_gcs+', file)) or (re.search(r'[a-zA-Z]_gcs+', file)):\n",
    "            full_path = f'{delete_file_path}{file}'\n",
    "            print(full_path)\n",
    "            os.remove(full_path)\n",
    "            print(f'removed {file}')\n",
    "    \n",
    "    # gaining a list of all the files in the given folder\n",
    "    shp_files = [f for f in os.listdir(shp_dir) if f.endswith('.shp')]\n",
    "\n",
    "    count = 0\n",
    "    # Iterate directory\n",
    "    for path in os.listdir(shp_dir):\n",
    "        # check if current path is a file\n",
    "        if path.endswith('.shp'):\n",
    "            count += 1\n",
    "    print(f'Downloading data for {count} files')\n",
    "    \n",
    "    index_num = -1\n",
    "    for shp_file in shp_files:\n",
    "        # increase the index by one for file searching and for creation later\n",
    "        index_num = index_num + 1\n",
    "        file_name_split = shp_file.split(\".\")\n",
    "        \n",
    "        # create the path to the start shapefile (polygon area)\n",
    "        shp_path = os.path.join(shp_dir, shp_file)\n",
    "        # create a feature collection from the feature\n",
    "        feature_collection = geemap.shp_to_ee(shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_metrics_df(given_directory):\n",
    "    # graph_type\n",
    "    threshold_dist = []\n",
    "    # to easily find the year\n",
    "    years = []\n",
    "    densitys = []\n",
    "    avg_path_lengths = []\n",
    "    diameters = []\n",
    "    transitivitys = []\n",
    "    clusters = []\n",
    "    mean_clusters = []\n",
    "    max_cluster_sizes = []\n",
    "\n",
    "    adjacency_files = [f for f in os.listdir(given_directory) if f.endswith('.adjacency')]\n",
    "\n",
    "    for adj_file in adjacency_files:\n",
    "        # use regex terms to find the year and the threshold distance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
